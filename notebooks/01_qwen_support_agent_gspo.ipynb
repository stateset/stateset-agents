{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Qwen Technical Support Agent \u2014 GSPO Fine-tuning\n",
        "\n",
        "This notebook fine-tunes a Qwen model for **technical support** using **GSPO + LoRA**.\n",
        "\n",
        "Notes:\n",
        "- Start with a smaller model (3B) to validate your setup.\n",
        "- If you scale to 7B, you\u2019ll likely want `use_4bit=True`.\n",
        "- This GSPO implementation uses a prompt set (from environment scenarios) + a reward model.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
        "os.environ.setdefault(\"WANDB_MODE\", \"disabled\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Pick a base model\n",
        "MODEL_NAME = \"Qwen/Qwen2.5-3B-Instruct\"  # try 7B with use_4bit=True\n",
        "OUTPUT_DIR = \"./outputs/notebooks/qwen_support_gspo\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from stateset_agents import MultiTurnAgent\n",
        "from stateset_agents.core.agent import AgentConfig\n",
        "from stateset_agents.core.environment import ConversationEnvironment, CONVERSATION_CONFIGS\n",
        "from stateset_agents.rewards import create_domain_reward\n",
        "from stateset_agents.training import GSPOConfig, train_with_gspo\n",
        "\n",
        "# Build a small prompt set from environment scenarios.\n",
        "env_config = CONVERSATION_CONFIGS[\"technical_support\"].copy()\n",
        "env_config[\"scenarios\"] = env_config[\"scenarios\"] + [\n",
        "    {\n",
        "        \"topic\": \"install_error\",\n",
        "        \"user_goal\": \"Fix installation failure\",\n",
        "        \"context\": \"The installer fails with an error code. Provide step-by-step troubleshooting.\",\n",
        "    },\n",
        "    {\n",
        "        \"topic\": \"update_regression\",\n",
        "        \"user_goal\": \"Recover after a bad update\",\n",
        "        \"context\": \"After updating, the app won\u2019t open. Suggest rollback/reinstall and log collection.\",\n",
        "    },\n",
        "    {\n",
        "        \"topic\": \"login_issue\",\n",
        "        \"user_goal\": \"Fix login failures\",\n",
        "        \"context\": \"User can\u2019t log in and sees an authentication error. Provide diagnosis steps.\",\n",
        "    },\n",
        "    {\n",
        "        \"topic\": \"performance_issue\",\n",
        "        \"user_goal\": \"Improve slow performance\",\n",
        "        \"context\": \"The system is slow. Provide a prioritized checklist (resources, drivers, background apps).\",\n",
        "    },\n",
        "    {\n",
        "        \"topic\": \"network_troubleshooting\",\n",
        "        \"user_goal\": \"Restore network connectivity\",\n",
        "        \"context\": \"Wi-Fi connects but there\u2019s no internet. Provide OS/network troubleshooting steps.\",\n",
        "    },\n",
        "]\n",
        "\n",
        "environment = ConversationEnvironment(**env_config)\n",
        "reward_model = create_domain_reward(\"technical_support\")\n",
        "\n",
        "system_prompt = (\n",
        "    \"You are Qwen, a knowledgeable technical support specialist. \"\n",
        "    \"Ask concise clarifying questions, then provide step-by-step fixes, \"\n",
        "    \"including verification steps and safe fallback options.\"\n",
        ")\n",
        "\n",
        "# Do NOT call agent.initialize() here: GSPO will load the model once and attach it.\n",
        "agent = MultiTurnAgent(\n",
        "    AgentConfig(\n",
        "        model_name=MODEL_NAME,\n",
        "        system_prompt=system_prompt,\n",
        "        max_new_tokens=384,\n",
        "        temperature=0.7,\n",
        "    ),\n",
        "    memory_window=8,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Training config tuned for a laptop GPU.\n",
        "# Increase num_outer_iterations and add more scenarios for real training.\n",
        "\n",
        "config = GSPOConfig(\n",
        "    model_name=MODEL_NAME,\n",
        "    output_dir=OUTPUT_DIR,\n",
        "    report_to=\"none\",\n",
        "    # \"iterations\" in this GSPO implementation\n",
        "    num_outer_iterations=5,\n",
        "    num_iterations=1,\n",
        "    generations_per_iteration=len(environment.scenarios),\n",
        "    # group size (responses per prompt)\n",
        "    num_generations=4,\n",
        "    # memory/perf knobs\n",
        "    use_lora=True,\n",
        "    lora_r=32,\n",
        "    lora_alpha=64,\n",
        "    lora_dropout=0.05,\n",
        "    gradient_checkpointing=True,\n",
        "    use_4bit=False,\n",
        "    use_8bit=False,\n",
        "    bf16=True,\n",
        "    per_device_train_batch_size=1,\n",
        "    gradient_accumulation_steps=8,\n",
        "    learning_rate=8e-6,\n",
        "    max_prompt_length=512,\n",
        "    max_completion_length=384,\n",
        "    temperature=0.7,\n",
        "    top_p=0.9,\n",
        "    logging_steps=1,\n",
        "    save_steps=2,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "trained_agent = await train_with_gspo(\n",
        "    config=config,\n",
        "    agent=agent,\n",
        "    environment=environment,\n",
        "    reward_model=reward_model,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Quick sanity check\n",
        "test_messages = [\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": \"My app crashes on launch after the latest update. What should I do?\",\n",
        "    }\n",
        "]\n",
        "\n",
        "print(await trained_agent.generate_response(test_messages))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Artifacts\n",
        "\n",
        "- Checkpoints: `OUTPUT_DIR/checkpoint-*`\n",
        "- Final save: `OUTPUT_DIR/final_model`\n",
        "\n",
        "If `use_lora=True`, the saved folder is a **LoRA adapter** (not the full base model).\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "pygments_lexer": "ipython3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}

